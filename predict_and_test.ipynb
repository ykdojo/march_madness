{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from time import time\n",
      "results = pd.read_csv(\"data/tourney_results.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test the prediction method with all the seasons\n",
      "seeds = pd.read_csv(\"data/tourney_seeds.csv\")\n",
      "scores = pd.read_csv(\"data/regular_season_results.csv\")\n",
      "results = pd.read_csv(\"data/tourney_results.csv\")\n",
      "all_actual_scores = pd.Series(dtype='int')\n",
      "all_pred_scores = pd.Series(dtype='float64')\n",
      "\n",
      "# test with all the seasons\n",
      "seasons  = map(chr, range(ord('A'), ord('R') + 1))\n",
      "accuracy_array = np.array([0,0]) # stores [accurate_predictions, num_predictions]\n",
      "x_hat_list = []\n",
      "\n",
      "t0 = time() # benchmark the 18 iterations\n",
      "for season in seasons:\n",
      "#    teams = np.array(seeds[seeds['season'] == season]['team']) # easier to work with numpy array than panda series\n",
      "    teams = xrange(501, 857) # TODO: DOING NOW: use ALL the teams for this calculation\n",
      "    \n",
      "    # record the matrix index for each team\n",
      "    team_dict = {}\n",
      "    for i in range(len(teams)):\n",
      "        teams[i]\n",
      "        team_dict[ teams[i] ] = i\n",
      "    \n",
      "    # Just get the current season\n",
      "    current = scores[scores['season'] == season]\n",
      "    \n",
      "    # The following is useful if we have a limited number of teams in our model\n",
      "    if_in_team_dict = np.repeat(True, len(current))\n",
      "    for i in range(len(if_in_team_dict)):\n",
      "        if_in_team_dict[i] = current['wteam'].iloc[i] in team_dict and current['lteam'].iloc[i] in team_dict\n",
      "    train = current[if_in_team_dict]\n",
      "    test = results[results['season'] == season]\n",
      "    \n",
      "    # game incidence matrix (winner = +1, loser = -1)\n",
      "    G = np.zeros([len(train), len(teams)])\n",
      "    \n",
      "    # for each row\n",
      "    for i in range( len(train) ):\n",
      "        # index for winning/losing team\n",
      "        row = train.iloc[i,]\n",
      "        i_win = team_dict[ row['wteam'] ]\n",
      "        i_lose = team_dict[ row['lteam'] ]\n",
      "        G[i, i_win] = 1; G[i, i_lose] = -1\n",
      "        \n",
      "    train['score_diffs'] = train['wscore'] - train['lscore']\n",
      "    \n",
      "    x_hat = np.linalg.lstsq(G, np.array(train['score_diffs']))[0]\n",
      "    x_hat_list.append(x_hat)\n",
      "    \n",
      "    # input the guess score difference\n",
      "    wteam_potential = test['wteam'].map(lambda t: x_hat[ team_dict[t] ])\n",
      "    lteam_potential = test['lteam'].map(lambda t: x_hat[ team_dict[t] ])\n",
      "    test['pred_scores'] = wteam_potential - lteam_potential\n",
      "    all_pred_scores = pd.concat([ all_pred_scores, test['pred_scores'] ])\n",
      "    all_actual_scores = pd.concat([ all_actual_scores, test['wscore'] - test['lscore'] ])\n",
      "    test['prediction'] = test['pred_scores'] > 0 # prediction that the 'wteam' will win (if True, then this is accurate)\n",
      "\n",
      "    \n",
      "    # add to the accuracy array ([num_correct_predictions, num_precitions])\n",
      "    accuracy_array += np.array([ sum(test['prediction']), len(test['prediction']) ])\n",
      "time_passed = time() - t0\n",
      "time_passed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 53,
       "text": [
        "20.508933067321777"
       ]
      }
     ],
     "prompt_number": 53
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_estimate = float(accuracy_array[0]) / accuracy_array[1]\n",
      "\n",
      "# CI = confidence interval\n",
      "CI_length = 1.3 / np.sqrt( accuracy_array[1] ) \n",
      "# 99% CI ([lower_bound, upper_bound])\n",
      "CI_99_percent = np.array([accuracy_estimate - CI_length, accuracy_estimate + CI_length])\n",
      "\n",
      "print \"accuracy (99% CI): \", CI_99_percent\n",
      "print \"correlation coefficient:\", np.corrcoef(all_actual_scores, all_pred_scores)[0][1]\n",
      "print \"max, min (pred):\", all_pred_scores.max(), \",\", all_pred_scores.min()\n",
      "#print \"max, min (actual):\", all_actual_scores.max(), \",\", all_actual_scores.min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "accuracy (99% CI):  [ 0.66418685  0.74065744]\n",
        "correlation coefficient: 0.456181374908\n",
        "max, min (pred): 62.515625 , -47.9375\n"
       ]
      }
     ],
     "prompt_number": 54
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in x_hat_list:\n",
      "    print x.max() - x.min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.36896222292e+16\n",
        "2.9456318407e+16\n",
        "2.71696481237e+16\n",
        "2.07250504246e+16\n",
        "2.88017924914e+16\n",
        "1.9606380809e+16\n",
        "2.25666721651e+16\n",
        "1.84773744539e+16\n",
        "2.88249907911e+16\n",
        "2.87959425083e+16\n",
        "1.84869807301e+16\n",
        "3.44403519136e+16\n",
        "9.48643458297e+15\n",
        "2.38430724392e+16\n",
        "1.04482880587e+16\n",
        "2.33987004776e+16\n",
        "5.58020657322e+15\n",
        "1.07938615612e+16\n"
       ]
      }
     ],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(all_actual_scores, all_pred_scores)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    }
   ],
   "metadata": {}
  }
 ]
}