{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from time import time\n",
      "results = pd.read_csv(\"data/tourney_results.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# test the prediction method with all the seasons\n",
      "seeds = pd.read_csv(\"data/tourney_seeds.csv\")\n",
      "scores = pd.read_csv(\"data/regular_season_results.csv\")\n",
      "results = pd.read_csv(\"data/tourney_results.csv\")\n",
      "all_actual_scores = pd.Series(dtype='int')\n",
      "all_pred_scores = pd.Series(dtype='float64')\n",
      "\n",
      "# test with all the seasons\n",
      "# DOING: test with 17 seasons, use 1.5 seasons for training #TODO: fix later?\n",
      "seasons  = map(chr, range(ord('B'), ord('R') + 1)) # iterate from season 'A' to 'R'\n",
      "accuracy_array = np.array([0,0]) # stores [accurate_predictions, num_predictions]\n",
      "x_hat_list = []\n",
      "\n",
      "t0 = time() # benchmark the 18 iterations\n",
      "for season in seasons:\n",
      "    teams = np.array(seeds[seeds['season'] == season]['team']) # easier to work with numpy array than panda series\n",
      "#    teams = xrange(501, 857) # TODO: DOING NOW: use ALL the teams for this calculation\n",
      "    \n",
      "    # record the matrix index for each team\n",
      "    team_dict = {}\n",
      "    for i in range(len(teams)):\n",
      "        teams[i]\n",
      "        team_dict[ teams[i] ] = i\n",
      "    \n",
      "#  The following is useful if we have a limited number of teams in our model\n",
      "    temp = pd.concat([ scores[scores['season'] == chr( ord(season) - 1)], scores[scores['season'] == season] ])\n",
      "    if_in_team_dict = np.repeat(True, len(temp))\n",
      "    for i in range(len(if_in_team_dict)):\n",
      "        if_in_team_dict[i] = temp['wteam'].iloc[i] in team_dict and temp['lteam'].iloc[i] in team_dict\n",
      "    train = temp[if_in_team_dict]\n",
      "    test = results[results['season'] == season]\n",
      "    \n",
      "    # game incidence matrix (winner = +1, loser = -1)\n",
      "    G = np.zeros([len(train), len(teams)])\n",
      "    \n",
      "    # for each row\n",
      "    for i in range( len(train) ):\n",
      "        # index for winning/losing team\n",
      "        row = train.iloc[i,]\n",
      "        i_win = team_dict[ row['wteam'] ]\n",
      "        i_lose = team_dict[ row['lteam'] ]\n",
      "        G[i, i_win] = 1; G[i, i_lose] = -1\n",
      "        \n",
      "    train['score_diffs'] = train['wscore'] - train['lscore']\n",
      "    \n",
      "    x_hat = np.linalg.lstsq(G, np.array(train['score_diffs']))[0]\n",
      "    x_hat_list.append(x_hat)\n",
      "    \n",
      "    # input the guess score difference\n",
      "    wteam_potential = test['wteam'].map(lambda t: x_hat[ team_dict[t] ])\n",
      "    lteam_potential = test['lteam'].map(lambda t: x_hat[ team_dict[t] ])\n",
      "    test['pred_scores'] = wteam_potential - lteam_potential\n",
      "    all_pred_scores = pd.concat([ all_pred_scores, test['pred_scores'] ])\n",
      "    all_actual_scores = pd.concat([ all_actual_scores, test['wscore'] - test['lscore'] ])\n",
      "    test['prediction'] = test['pred_scores'] > 0 # prediction that the 'wteam' will win (if True, then this is accurate)\n",
      "\n",
      "    \n",
      "    # add to the accuracy array ([num_correct_predictions, num_precitions])\n",
      "    accuracy_array += np.array([ sum(test['prediction']), len(test['prediction']) ])\n",
      "time_passed = time() - t0\n",
      "time_passed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "4.647412061691284"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 42,
       "text": [
        "4.680201053619385"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "accuracy_estimate = float(accuracy_array[0]) / accuracy_array[1]\n",
      "\n",
      "# CI = confidence interval\n",
      "CI_length = 1.3 / np.sqrt( accuracy_array[1] ) \n",
      "# 99% CI ([lower_bound, upper_bound])\n",
      "CI_99_percent = np.array([accuracy_estimate - CI_length, accuracy_estimate + CI_length])\n",
      "\n",
      "print \"time passed: \", time_passed\n",
      "print \"accuracy (99% CI): \", CI_99_percent\n",
      "print \"correlation coefficient:\", np.corrcoef(all_actual_scores, all_pred_scores)[0][1]\n",
      "print \"max, min (pred):\", all_pred_scores.max(), \",\", all_pred_scores.min()\n",
      "#print \"max, min (actual):\", all_actual_scores.max(), \",\", all_actual_scores.min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "time passed:  4.68020105362\n",
        "accuracy (99% CI):  [ 0.62947967  0.70812325]\n",
        "correlation coefficient: 0.00768769375095\n",
        "max, min (pred): 1.57739499646e+15 , -1.28214937204e+16\n"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x in x_hat_list:\n",
      "    print x.max() - x.min()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2.15086359179e+16\n",
        "1.86314495515e+16\n",
        "1.82286783796e+16\n",
        "1.57329630484e+16\n",
        "1.86402034898e+16\n",
        "1.81238114219e+16\n",
        "1.34620429322e+16\n",
        "1.31005113922e+16\n",
        "1.72384874715e+16\n",
        "1.7876903646e+16\n",
        "1.07944827163e+16\n",
        "1.10786835571e+16\n",
        "2.64087579509e+15\n",
        "2.28292874699e+16\n",
        "8.58965338007e+15\n",
        "1.00386987897e+16\n",
        "1.21416329014e+15\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.scatter(all_actual_scores, all_pred_scores)\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    }
   ],
   "metadata": {}
  }
 ]
}